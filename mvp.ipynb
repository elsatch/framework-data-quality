{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/dottyz/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "import datetime\n",
    "\n",
    "import ckanapi\n",
    "import geopandas as gpd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import petk\n",
    "import requests\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from shapely.geometry import mapping, shape, Point, LineString, Polygon\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from time import sleep\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_FRAMEWORK = 'catalogue-quality-scores'\n",
    "\n",
    "RESOURCE_METHODS = 'scoring-methods'\n",
    "RESOURCE_SCORES = 'catalogue-scorecard'\n",
    "\n",
    "MODEL_VERSION = 'v0.0.2'\n",
    "\n",
    "DIMENSIONS = ['interpretability', 'usability', 'metadata', 'freshness', 'granularity', 'completeness', 'accessibility'] # Ordered by importance\n",
    "\n",
    "METADATA_FIELDS = ['collection_method', 'limitations', 'civic_issues', 'topics', 'owner_division', 'owner_email']\n",
    "\n",
    "DATA_CKAN = {\n",
    "    'address': 'https://ckan0.cf.opendata.inter.prod-toronto.ca'\n",
    "#     'apikey': ''\n",
    "}\n",
    "\n",
    "STORAGE_CKAN = {\n",
    "    'address': 'https://ckanadmin0.intra.dev-toronto.ca',\n",
    "    'apikey': '784f11cc-b170-4377-83a3-38ba28662b16'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(ckan, pid=PACKAGE_FRAMEWORK):\n",
    "    try:\n",
    "        model = ckan.action.package_show(id=pid)\n",
    "    except ckanapi.NotAuthorized:\n",
    "        raise Exception('Permission required to search for the framework package')\n",
    "    except ckanapi.NotFound:\n",
    "        raise Exception('Framework package not found')\n",
    "    \n",
    "    return {\n",
    "        r['name']: r for r in model.pop('resources')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datastore(ckan, rid, rows=10000):\n",
    "    records = []\n",
    "    \n",
    "    is_geospatial = False\n",
    "    \n",
    "    has_more = True\n",
    "    while has_more:\n",
    "        result = ckan.action.datastore_search(id=rid, limit=rows, offset=len(records))\n",
    "        \n",
    "        records += result['records']\n",
    "        has_more = len(records) < result['total']\n",
    "    \n",
    "    df = pd.DataFrame(records).drop('_id', axis=1)\n",
    "    \n",
    "    if 'geometry' in df.columns:\n",
    "        df['geometry'] = df['geometry'].apply(lambda x: shape(json.loads(x)))\n",
    "        \n",
    "        df = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'})\n",
    "    \n",
    "    return df, [x for x in result['fields'] if x['id'] != '_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_usability(package, columns, data):\n",
    "    # TODO: once non-tabular data are passed through - measure the level of nested fields\n",
    "    \n",
    "    columns_meaningful = 0\n",
    "    columns_constant = 0\n",
    "    \n",
    "    for f in columns:\n",
    "        eng_words = [wordnet.synsets(x) for x in re.split('\\s|_|-', f['id'])]\n",
    "\n",
    "        if len([x for x in eng_words if len(x)]) / len(eng_words) > 0.8:\n",
    "            columns_meaningful += 1\n",
    "        \n",
    "        if f['id'] == 'geometry' or data[f['id']].nunique() == 1:\n",
    "            columns_constant += 1\n",
    "    \n",
    "    return np.mean([columns_meaningful / len(columns), 1 - columns_constant / len(columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_metadata(package, columns):\n",
    "    fields_filled = 0\n",
    "    for field in METADATA_FIELDS:\n",
    "        if field in package and not package[field] is None:\n",
    "            # TODO: measure the quality of the description\n",
    "            \n",
    "            fields_filled += 1\n",
    "            \n",
    "    columns_described = 0\n",
    "    for f in columns:\n",
    "        if 'info' in f and len(f['info']['notes']):\n",
    "            columns_described += 1\n",
    "\n",
    "    return np.mean([fields_filled/len(METADATA_FIELDS), columns_described / len(columns)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_freshness(package):\n",
    "    # TODO: measure the difference between last refreshed and current date\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(dimensions, data, method='sr'):\n",
    "    for i, row in enumerate(data):\n",
    "        row['dimensions'] = {}\n",
    "        for dim, fields in METRICS.items():\n",
    "            scores = [ row['metrics'][x] for x in fields ]\n",
    "\n",
    "            row[dim] = sum(scores)/len(scores)\n",
    "\n",
    "    N = len(dimensions)\n",
    "    \n",
    "    if method == 'sr':\n",
    "        denom = np.array([ ((1 / (i + 1)) + ((N + 1 - (i + 1)) / N)) for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ ((1 / (i + 1)) + ((N + 1 - (i + 1)) / N)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 'rs':\n",
    "        denom = np.array([ (N + 1 - (i + 1)) for i, x in enumerate(dimensions)]).sum()\n",
    "        weights = [ (N + 1 - (i + 1)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 'rr':\n",
    "        denom = np.array([ 1 / (i + 1) for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ (1 / (i + 1)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 're':\n",
    "        exp = 0.2\n",
    "        denom = np.array([ (N + 1 - (i + 1)) ** exp for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ (N + 1 - (i + 1)) ** exp / denom for i, x in enumerate(dimensions) ]\n",
    "    else:\n",
    "        raise Exception('Invalid weighting method provided')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(ckan, model, storage):\n",
    "    if not RESOURCE_METHODS in storage:\n",
    "        r = requests.post(\n",
    "            '{0}/api/3/action/resource_create'.format(ckan.address),\n",
    "            data={\n",
    "                'package_id': PACKAGE_FRAMEWORK,\n",
    "                'name': RESOURCE_METHODS,\n",
    "                'format': 'json',\n",
    "                'is_preview': False\n",
    "            },\n",
    "            headers={\n",
    "                'Authorization': ckan.apikey\n",
    "            },\n",
    "            files={\n",
    "                'upload': ('{0}.json'.format(RESOURCE_METHODS), json.dumps({}))\n",
    "            }\n",
    "        )\n",
    "\n",
    "        storage[RESOURCE_METHODS] = json.loads(r.content)['result']\n",
    "\n",
    "    r = requests.get(\n",
    "        storage[RESOURCE_METHODS]['url'],\n",
    "        headers={\n",
    "            'Authorization': ckan.apikey\n",
    "        }\n",
    "    )\n",
    "\n",
    "    scoring_methods = json.loads(r.content)\n",
    "    scoring_methods[MODEL_VERSION] = model\n",
    "\n",
    "    r = requests.post(\n",
    "        '{0}/api/3/action/resource_patch'.format(ckan.address),\n",
    "        data={\n",
    "            'id': storage[RESOURCE_METHODS]['id']\n",
    "        },\n",
    "        headers={\n",
    "            'Authorization': ckan.apikey\n",
    "        },\n",
    "        files={\n",
    "            'upload': ('{0}.json'.format(RESOURCE_METHODS), json.dumps(scoring_methods))\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_score(ckan, data, weight, dimensions, storage):\n",
    "    df = pd.DataFrame(data).set_index(['package', 'resource'])\n",
    "\n",
    "    scores = pd.DataFrame([weight] * len(df.index))\n",
    "    scores.index = df.index\n",
    "    scores.columns = dimensions\n",
    "\n",
    "    scores = df.multiply(scores)\n",
    "\n",
    "    df['score'] = scores.sum(axis=1)\n",
    "    df['score_norm'] = MinMaxScaler().fit_transform(df[['score']])\n",
    "\n",
    "    df = df.groupby('package').mean()\n",
    "\n",
    "    df['grade'] = pd.cut(df['score'], bins=[-1, .3, .5, .8, 1], labels=['D','C','B','A'])\n",
    "    df['grade_norm'] = pd.cut(df['score_norm'], bins=[-1, .3, .5, .8, 1], labels=['D','C','B','A'])\n",
    "\n",
    "    df['recorded_at'] = dt.now()\n",
    "    df['model'] = MODEL_VERSION\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    report = petk.DataReport(df).describe(as_dict=True)\n",
    "\n",
    "    ckan_fields = {\n",
    "        'STRING': 'text',\n",
    "        'NUMERIC': 'float',\n",
    "        'DATE': 'timestamp'\n",
    "    }\n",
    "\n",
    "    fields = [\n",
    "        {\n",
    "            'id': k,\n",
    "            'type': ckan_fields[v]\n",
    "        } for k, v in report['content_type'].items()\n",
    "    ]\n",
    "\n",
    "    if not RESOURCE_SCORES in storage:\n",
    "        storage[RESOURCE_SCORES] = ckan.action.datastore_create(\n",
    "            resource={\n",
    "                'package_id': PACKAGE_FRAMEWORK,\n",
    "                'name': RESOURCE_SCORES,\n",
    "                'format': 'csv',\n",
    "                'is_preview': False\n",
    "            },\n",
    "            fields=fields,\n",
    "            records=[]\n",
    "        )\n",
    "\n",
    "    df['recorded_at'] = df['recorded_at'].apply(lambda x: x.strftime('%Y-%m-%dT%H:%M:%SZ'))\n",
    "\n",
    "    ckan.action.datastore_upsert(\n",
    "        method='insert',\n",
    "        resource_id=storage[RESOURCE_SCORES]['resource_id'],\n",
    "        records=df.to_dict(orient='row')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "source = ckanapi.RemoteCKAN(**DATA_CKAN)\n",
    "ckan = ckanapi.RemoteCKAN(**STORAGE_CKAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "storage = get_model(ckan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ytan/miniconda3/envs/open-data/lib/python3.7/site-packages/petk/tools.py:63: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  'cv': series.std() / series.mean(),\n"
     ]
    }
   ],
   "source": [
    "packages = ckan.action.current_package_list_with_resources(limit=500)\n",
    "\n",
    "results = []\n",
    "for p in packages:\n",
    "    for r in p['resources']:\n",
    "        if not 'datastore_active' in r or not r['datastore_active']:\n",
    "            continue\n",
    "        \n",
    "        data, fields = read_datastore(ckan, r['id'])\n",
    "        \n",
    "        results.append({\n",
    "            'package': p['name'],\n",
    "            'resource': r['name'],\n",
    "            'metrics': {\n",
    "#                 'interpretability': 1,\n",
    "                'usability': score_usability(p, fields, data),\n",
    "                'metadata': score_metadata(p, fields),\n",
    "#                 'freshness': score_freshness(p),\n",
    "#                 'granularity': 1,\n",
    "                'completeness': 1 - (np.sum(len(data) - data.count()) / np.prod(data.shape)),\n",
    "                'accessibility': 1\n",
    "            }\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = [ x for x in DIMENSIONS if x in METRICS ]\n",
    "weights = calculate_weights(dimensions, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {\n",
    "    'aggregation_methods': {\n",
    "        'metrics_to_dimension': 'avg',\n",
    "        'dimensions_to_score': 'sum_and_reciprocal'\n",
    "    },\n",
    "    'dimensions': [\n",
    "        {\n",
    "            'name': dim,\n",
    "            'rank': i + 1,\n",
    "            'weight': wgt,\n",
    "            'metrics': METRICS[dim]\n",
    "        } for i, (dim, wgt) in enumerate(zip(dimensions, weights))\n",
    "    ]\n",
    "}\n",
    "\n",
    "update_model(ckan, model, storage)\n",
    "update_score(ckan, data, weights, dimensions, storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "\n",
    "is_geospatial = False\n",
    "\n",
    "has_more = True\n",
    "while has_more:\n",
    "    result = source.action.datastore_search(id='b9214fd7-60d1-45f3-8463-a6bd9828f8bf', limit=5000, offset=len(records))\n",
    "\n",
    "    records += result['records']\n",
    "    has_more = len(records) < result['total']\n",
    "\n",
    "df = pd.DataFrame(records).drop('_id', axis=1)\n",
    "\n",
    "if 'geometry' in df.columns:\n",
    "    df['geometry'] = df['geometry'].apply(lambda x: shape(json.loads(x)))\n",
    "\n",
    "    df = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
