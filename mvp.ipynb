{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import math\n",
    "import re\n",
    "\n",
    "import ckanapi\n",
    "import geopandas as gpd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "from shapely.geometry import mapping, shape\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from datetime import datetime as dt\n",
    "from time import sleep\n",
    "\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PACKAGE_FRAMEWORK = 'catalogue-quality-scores'\n",
    "\n",
    "RESOURCE_FRAMEWORK = 'scoring-methods'\n",
    "RESOURCE_SCORES = 'catalogue-scorecard'\n",
    "\n",
    "FRAMEWORK_VERSION = 'v0.1.0'\n",
    "\n",
    "# DIMENSIONS = ['interpretability', 'usability', 'metadata', 'freshness', 'granularity', 'completeness', 'accessibility'] # Ordered by importance\n",
    "DIMENSIONS = ['usability', 'metadata', 'freshness', 'completeness', 'accessibility'] # Ordered by importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_framework(ckan, pid=PACKAGE_FRAMEWORK):\n",
    "    try:\n",
    "        framework = ckan.action.package_show(id=pid)\n",
    "    except ckanapi.NotAuthorized:\n",
    "        raise Exception('Permission required to search for the framework package')\n",
    "    except ckanapi.NotFound:\n",
    "        raise Exception('Framework package not found')\n",
    "    \n",
    "    return {\n",
    "        r['name']: r for r in framework.pop('resources')\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_datastore(ckan, rid, rows=10000):\n",
    "    records = []\n",
    "    \n",
    "    is_geospatial = False\n",
    "    \n",
    "    has_more = True\n",
    "    while has_more:\n",
    "        result = ckan.action.datastore_search(id=rid, limit=rows, offset=len(records))\n",
    "        \n",
    "        records += result['records']\n",
    "        has_more = len(records) < result['total']\n",
    "    \n",
    "    df = pd.DataFrame(records).drop('_id', axis=1)\n",
    "    \n",
    "    if 'geometry' in df.columns:\n",
    "        df['geometry'] = df['geometry'].apply(lambda x: shape(json.loads(x)))\n",
    "        \n",
    "        df = gpd.GeoDataFrame(df, crs={'init': 'epsg:4326'})\n",
    "    \n",
    "    return df, [x for x in result['fields'] if x['id'] != '_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_usability(columns, data):\n",
    "    '''\n",
    "        How easy is it to use the data given how it is organized/structured?\n",
    "        \n",
    "        TODO's: \n",
    "            * level of nested fields?\n",
    "            * long vs. wide?\n",
    "            * if ID columns given, are these ID's common across datasets?\n",
    "    '''\n",
    "    \n",
    "    def parse_col_name(s):\n",
    "        camel_to_snake = re.sub(\n",
    "            '([a-z0-9])([A-Z])', \n",
    "            r'\\1_\\2', \n",
    "            re.sub('(.)([A-Z][a-z]+)', r'\\1_\\2', s)\n",
    "        ).lower()\n",
    "\n",
    "        return camel_to_snake == s, [x for x in re.split('-|_|\\s', camel_to_snake) if len(x)]\n",
    "\n",
    "    metrics = {\n",
    "        'col_names': 0, # Are the column names easy to understand?\n",
    "        'col_constant': 1 # Are there columns where all values are constant?\n",
    "    }\n",
    "    \n",
    "    for f in columns:\n",
    "        is_camel, words = parse_col_name(f['id'])\n",
    "        eng_words = [ w for w in words if len(wordnet.synsets(w)) ]\n",
    "\n",
    "        if len(eng_words) / len(words) > 0.8:\n",
    "            metrics['col_names'] += (1 if not is_camel else 0.5) / len(columns)\n",
    "        \n",
    "        if not f['id'] == 'geometry' and data[f['id']].nunique() <= 1:\n",
    "            metrics['col_constant'] -= 1 / len(columns)\n",
    "    \n",
    "    if isinstance(data, gpd.GeoDataFrame):\n",
    "        counts = data['geometry'].is_valid.value_counts()\n",
    "        \n",
    "        metrics['geo_validity'] = 1 - (counts[False] / (len(data) * 0.05)) if False in counts else 1\n",
    "    \n",
    "    return np.mean(list(metrics.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "METADATA_FIELDS = ['collection_method', 'limitations', 'topics', 'owner_email']\n",
    "\n",
    "def score_metadata(package, columns):\n",
    "    '''\n",
    "        How easy is it to understand the context of the data?\n",
    "        \n",
    "        TODO's: \n",
    "            * Measure the quality of the metadata as well\n",
    "    '''\n",
    "    \n",
    "    metrics = {\n",
    "        'desc_dataset': 0, # Does the metadata describe the dataset well?\n",
    "        'desc_columns': 0 # Does the metadata describe the data well?\n",
    "    }\n",
    "    \n",
    "    for field in METADATA_FIELDS:\n",
    "        if field in package and package[field] and not (field == 'owner_email' and 'opendata' in package[field]):\n",
    "            metrics['desc_dataset'] += 1 / len(METADATA_FIELDS)\n",
    "            \n",
    "    for f in columns:\n",
    "        if 'info' in f and len(f['info']['notes']) and f['info']['notes'].strip() != f['id']:\n",
    "            metrics['desc_columns'] += 1 / len(columns)\n",
    "\n",
    "    return np.mean(list(metrics.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_MAP = {\n",
    "    'read-time': 1,\n",
    "    'daily': 1,\n",
    "    'weekly': 7,\n",
    "    'monthly': 30,\n",
    "    'quarterly': 52 * 7 / 4,\n",
    "    'semi-annually': 52 * 7 / 2,\n",
    "    'annually': 365\n",
    "}\n",
    "\n",
    "def score_freshness(package):\n",
    "    '''\n",
    "        How up to date is the data?\n",
    "    '''\n",
    "    \n",
    "    metrics = {}\n",
    "    \n",
    "    rr = package['refresh_rate'].lower()\n",
    "    if rr in TIME_MAP and 'last_refreshed' in package and package['last_refreshed']: \n",
    "        days = (dt.now() - dt.strptime(package['last_refreshed'], '%Y-%m-%dT%H:%M:%S.%f')).days\n",
    "        \n",
    "        # Greater than 2 periods have a score of 0\n",
    "        metrics['elapse_periods'] = max(0, 1 - math.floor(days / TIME_MAP[rr]) / 2)\n",
    "        \n",
    "        # Decrease the score starting from ~0.5 years to ~3 years\n",
    "        metrics['elapse_days'] = 1 - (1 / (1 + np.exp(4 * (2.25 - days/365))))\n",
    "        \n",
    "        return np.mean(list(metrics.values()))\n",
    "    \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weights(dimensions, method='sr'):\n",
    "    N = len(dimensions)\n",
    "    \n",
    "    if method == 'sr':\n",
    "        denom = np.array([ ((1 / (i + 1)) + ((N + 1 - (i + 1)) / N)) for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ ((1 / (i + 1)) + ((N + 1 - (i + 1)) / N)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 'rs':\n",
    "        denom = np.array([ (N + 1 - (i + 1)) for i, x in enumerate(dimensions)]).sum()\n",
    "        weights = [ (N + 1 - (i + 1)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 'rr':\n",
    "        denom = np.array([ 1 / (i + 1) for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ (1 / (i + 1)) / denom for i, x in enumerate(dimensions) ]\n",
    "    elif method == 're':\n",
    "        exp = 0.2\n",
    "        denom = np.array([ (N + 1 - (i + 1)) ** exp for i, x in enumerate(dimensions) ]).sum()\n",
    "        weights = [ (N + 1 - (i + 1)) ** exp / denom for i, x in enumerate(dimensions) ]\n",
    "    else:\n",
    "        raise Exception('Invalid weighting method provided')\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_response(code, message=''):\n",
    "    response = {\n",
    "        'statusCode': code,\n",
    "        'headers': {\n",
    "            'Access-Control-Allow-Origin': '*',\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if message:\n",
    "        response['body'] = message\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lambda_handler(event, context):\n",
    "    ckan = ckanapi.RemoteCKAN(**{\n",
    "        'address': 'https://ckanadmin0.intra.dev-toronto.ca',\n",
    "        'apikey': '784f11cc-b170-4377-83a3-38ba28662b16'\n",
    "    })\n",
    "    \n",
    "    prod = ckanapi.RemoteCKAN(**{\n",
    "        'address': 'https://ckanadmin0.intra.prod-toronto.ca'\n",
    "    })\n",
    "    \n",
    "    weights = calculate_weights(DIMENSIONS)\n",
    "    fw = {\n",
    "        'aggregation_methods': {\n",
    "            'metrics_to_dimension': 'avg',\n",
    "            'dimensions_to_score': 'sum_and_reciprocal'\n",
    "        },\n",
    "        'dimensions': [\n",
    "            {\n",
    "                'name': dim,\n",
    "                'rank': i + 1,\n",
    "                'weights': wgt,\n",
    "            } for i, (dim, wgt) in enumerate(zip(DIMENSIONS, weights))\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    packages = prod.action.current_package_list_with_resources(limit=500)\n",
    "\n",
    "    storage = get_framework(ckan)\n",
    "\n",
    "    data = []\n",
    "    for p in packages:\n",
    "        for r in p['resources']:\n",
    "            if not 'datastore_active' in r or not r['datastore_active']:\n",
    "                continue\n",
    "\n",
    "            content, fields = read_datastore(prod, r['id'])\n",
    "\n",
    "            data.append({\n",
    "                'package': p['name'],\n",
    "                'resource': r['name'],\n",
    "    #             'interpretability': 1,\n",
    "                'usability': score_usability(fields, content),\n",
    "                'metadata': score_metadata(p, fields),\n",
    "                'freshness': score_freshness(p),\n",
    "    #             'granularity': 1,\n",
    "                'completeness': 1 - (np.sum(len(content) - content.count()) / np.prod(content.shape)),\n",
    "                'accessibility': 1 if 'extract_job' in r and r['extract_job'] else 0.5\n",
    "            })\n",
    "    \n",
    "    if not RESOURCE_FRAMEWORK in storage:\n",
    "        r = requests.post(\n",
    "            '{0}/api/3/action/resource_create'.format(ckan.address),\n",
    "            data={\n",
    "                'package_id': PACKAGE_FRAMEWORK,\n",
    "                'name': RESOURCE_FRAMEWORK,\n",
    "                'format': 'json',\n",
    "                'is_preview': False,\n",
    "                'is_zipped': False\n",
    "            },\n",
    "            headers={\n",
    "                'Authorization': ckan.apikey\n",
    "            },\n",
    "            files={\n",
    "                'upload': ('{0}.json'.format(RESOURCE_FRAMEWORK), json.dumps({}))\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        storage[RESOURCE_FRAMEWORK] = json.loads(r.content)['result']\n",
    "\n",
    "    r = requests.get(\n",
    "        storage[RESOURCE_FRAMEWORK]['url'],\n",
    "        headers={\n",
    "            'Authorization': ckan.apikey\n",
    "        }\n",
    "    )\n",
    "\n",
    "    scoring_methods = json.loads(r.content)\n",
    "    scoring_methods[FRAMEWORK_VERSION] = fw\n",
    "\n",
    "    r = requests.post(\n",
    "        '{0}/api/3/action/resource_patch'.format(ckan.address),\n",
    "        data={\n",
    "            'id': storage[RESOURCE_FRAMEWORK]['id']\n",
    "        },\n",
    "        headers={\n",
    "            'Authorization': ckan.apikey\n",
    "        },\n",
    "        files={\n",
    "            'upload': ('{0}.json'.format(RESOURCE_FRAMEWORK), json.dumps(scoring_methods))\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    df = pd.DataFrame(data).set_index(['package', 'resource'])\n",
    "\n",
    "    scores = pd.DataFrame([weights] * len(df.index))\n",
    "    scores.index = df.index\n",
    "    scores.columns = DIMENSIONS\n",
    "\n",
    "    scores = df.multiply(scores)\n",
    "\n",
    "    df['score'] = scores.sum(axis=1)\n",
    "    df['score_norm'] = MinMaxScaler().fit_transform(df[['score']])\n",
    "\n",
    "    df = df.groupby('package').mean()\n",
    "\n",
    "    df['grade'] = pd.cut(df['score'], bins=[-1, .3, .5, .8, 1], labels=['D','C','B','A'])\n",
    "    df['grade_norm'] = pd.cut(df['score_norm'], bins=[-1, .3, .5, .8, 1], labels=['D','C','B','A'])\n",
    "\n",
    "    df['recorded_at'] = dt.now().strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "    df['version'] = FRAMEWORK_VERSION\n",
    "\n",
    "    df = df.reset_index()\n",
    "\n",
    "    if not RESOURCE_SCORES in storage:\n",
    "        storage[RESOURCE_SCORES] = ckan.action.datastore_create(\n",
    "            resource={\n",
    "                'package_id': PACKAGE_FRAMEWORK,\n",
    "                'name': RESOURCE_SCORES,\n",
    "                'format': 'csv',\n",
    "                'is_preview': False,\n",
    "                'is_zipped': True\n",
    "            },\n",
    "            records=df.to_dict(orient='row')\n",
    "        )\n",
    "    else:\n",
    "        ckan.action.datastore_upsert(\n",
    "            method='insert',\n",
    "            resource_id=storage[RESOURCE_SCORES]['id'],\n",
    "            records=df.to_dict(orient='row')\n",
    "        )\n",
    "    \n",
    "    build_response(200, message='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_handler('', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
